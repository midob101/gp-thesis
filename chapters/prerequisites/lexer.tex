
\subsection{Lexer}

The parsing process of a compiler is often divided into two parts. The first part is the lexer. 
The task of the lexer is to take the whole source code and create a token stream. 
The lexer works with regular expressions and avoids more complex implementations.

The lexer is a preparation for the parser, since it usually removes unwanted characters like whitespace and generalizes other tokens.
For example, any string matching the regular expression \verb|[a-zA-Z_][a-zA-Z_0-9]*| could be an identifier, and \verb|[0-9]+| would be an integer. 
The name identifier is often used for variable, function and class names in lexers. 
This way the parser only has to work with the abstraction, not with the real input.

The following example illustrates the purpose of the lexer process
\begin{lstlisting}[language=Java, caption="Example input for the lexer"]
int get_fixed_sum(int a) {
    return a + 19284;
}
\end{lstlisting}

The lexer will start parsing at the beginning, identify the first token, and continue. The resulting token stream might look like this.

\begin{lstlisting}[language=Java, caption="Example output of the lexer"]
int_type 
identifier
bracket_open
int_type
identifier
bracket_close
curly_bracket_open
return_stmt
identifier
add
number
semicolon
curly_bracket_close
\end{lstlisting}

Each line is a token. These tokens are used as terminal symbols in the grammar definition.

The implemented lexer works very similar, the only difference is that all tokens are maintained, including whitespaces and comments.

Further informations about the functionality and implementation of a lexer can be found in \cite[pages 109-189]{AhoLSU2006}.