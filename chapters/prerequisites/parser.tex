
\subsection{Parser}

The second part will perform the parsing on the token stream and by using the grammar rules. There are many kinds of parsers, the most common ones used in compiler development are:

\begin{enumerate}
\item LL(1): Scanning the input from left to right, applying leftmost deriviation, using one token of lookahead.
\item LR(1): Scanning the input from left to right, applying rightmost deriviation, using one token of lookahead.
\item LALR(1): A variation of LR(1), which reduces the amount of calculations and memory requirements.
\end{enumerate}

There are two goals of the parsing process. The first one is to verify that the input matches the grammar. The second one is to generate a tree structure, which represents the input. The tree structure generated by the parser is called a concrete syntax tree (CST). This tree structure is very verbose and represents the grammar definition exactly.

There are two main different ways used to parse source code. The first approach is top-down parsing. In top-down parsing, the root node will be generated first, following by the childrens and the leaf nodes will be generated at the end. LL(1) parsing is one example for top-down parsing. The other approach is bottom-down parsing. In this parsing strategy the leaf nodes are generated first and the root node is generated at the very end. LR(1) and LALR(1) are examples for bottom-down parsing algorithms.

The top-down parsers have the benefit of being rather easy to understand, however they are less powerfull. Bottom-down parsers are harder to understand and to debug, however they can parse more grammars.

Each of the presented grammars are not able to parse all context free grammars, but they are sufficient enough to parse most programming languages. LR(1) is the parsing strategy that is able to parse the most grammars, but requires the largest amount of memory and calculations to correctly parse.

As memory and runtime is not the main priority in this thesis, a LR(1) parser was implemented to allow the largest amount of grammars being parsed.


The LR(1) parsing strategy relies on two different tables. The construction of the tables is explained in \cite{AhoLSU2006}.

The following example is taken from \cite{AhoLSU2006}.

Let $N = \{S, C\}, \Sigma = \{c, d\}, S = S$ a grammar with the productions $P$ defined as

\begin{align}
P = \{&S \rightarrow C\text{ }C\\
&C \rightarrow c\text{ }C\\
&C \rightarrow d\}
\end{align}

Let r1 be a reference to the production rule $S \rightarrow C\text{ }C$, r2 be a reference to $C \rightarrow c\text{ }C$ and r3 be a reference to $C \rightarrow d$.

The first table is called an action table.

\begin{center}
\begin{tabular}{c|ccc}
State & $c$ & $d$ & \$\\
\hline 
0 & s3 & s4 & \\
1 &    &    & acc \\
2 & s6 & s7 & \\
3 & s3 & s4 & \\
4 & r3 & r3 & \\
5 & & & r1\\
6 & s6 & s7 & \\
7 & & & r3\\
8 & r2 & r2 & \\
9 & & & r2
\end{tabular} 
\end{center}


The rows represents different states. The columns represent the terminal symbols of the grammar. The value of each cell can be empty, a shift, a reduce or an accept action. 

A shift action will consume a token from the token stream and move to a new state. For example, s6 will perform a shift and move to state 6.

A reduce action will go back to a previously encountered state and references a grammar rule that is beeing reduced.

A accept action is only defined once in the entire table. Once this is encountered, the parsing process is finished and the input was successfully parsed.

The second table is the goto table. 

\begin{center}
\begin{tabular}{c|cc}
State & $S$ & $C$\\
\hline 
0 & 1 & 2\\
1 &    &     \\
2 &  & 5 \\
3 &  & 8  \\
4 &  &   \\
5 &  & \\
6 &  & 9 \\
7 &  & \\
8 &  &  \\
9 &  & 
\end{tabular} 
\end{center}

The rows represents the different states. The columns represent the non terminal symbols of the grammar. The content of each cell can either be a reference another state or empty.

The parser itself manages a stack of states. The top of the stack is the current state that is currently being processed. The parser reads the current token in the token stream provided by the lexer and receives the current action from the action table.
Based on the action type, different behaviours apply.

On a shift action, the parser will shift the position in the token stream and will continue in the next iteration with a new token. The new state defined in the shift action will be pushed on the stack. Then the next iteration is started.

On a reduce action, the parser will pop as $n$ states from the stack, where $n$ is equal to the amount of terminal and nonterminal symbols on the right hand side of the grammar rule. Afterwards, the new top of stack is beeing read and the state defined in the goto table of the top of stack and the current token in the token stream will be pushed on the stack.

On an accept action, the parser will finalize the parsing process accept the input. 
