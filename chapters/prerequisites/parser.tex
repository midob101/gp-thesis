
\subsection{Parser}

The second part will perform the parsing on the token stream and by using the grammar rules. 
There are many types of parsers, two of the common ones used in compiler development are

\begin{enumerate}
\item LL(1): Scanning the input from left to right, applying leftmost deriviation, using one token of lookahead.
\item LR(1): Scanning the input from left to right, applying rightmost deriviation, using one token of lookahead.
\end{enumerate}

There are two goals of the parsing process. 
The first is to verify that the input conforms to the grammar. 
The second is to generate a tree structure that represents the input. 
The tree structure generated by the parser is called a Concrete Syntax Tree (CST). 
This tree structure is very verbose and represents the grammar definition exactly.

There are two main ways to parse source code. 
The first is top-down parsing. 
In top-down parsing, the root node is created first, followed by the child nodes, and the leaf nodes are created at the end. 
LL(1) parsing is an example of top-down parsing. 
The other approach is called bottom-down parsing. 
In this parsing strategy, the leaf nodes are generated first, and the root node is generated at the very end. 
LR(1) is an example of a bottom-down parsing algorithm.

LL(1) has the advantage of being relatively easy to understand, but LL(1) is less powerful than LR(1). 
LR(1) parsers are harder to understand and debug, but can parse more grammars then LL(1).

Each of the presented grammars are not able to parse all context free grammars, but they are sufficient enough to parse most programming languages. 
LR(1) is a parsing strategy that is able to parse many grammars, but requires a large amount of memory and computation to parse correctly.

Since memory and runtime are not the main priority in this thesis, a LR(1) parser was implemented to allow a large number of grammars to be parsed.


The LR(1) parsing strategy relies on two different tables. The construction of the tables is explained in \cite{AhoLSU2006}.

The following example is taken from \cite{AhoLSU2006}.

Let $N = \{S, C\}, \Sigma = \{c, d\}, S = S$ a grammar with the productions $P$ defined as

\begin{align}
P = \{&S \rightarrow C\text{ }C\\
&C \rightarrow c\text{ }C\\
&C \rightarrow d\}
\end{align}

Let r1 be a reference to the production rule $S \rightarrow C\text{ }C$, r2 be a reference to $C \rightarrow c\text{ }C$ and r3 be a reference to $C \rightarrow d$.

The first table is called the action table.

\begin{center}
\begin{tabular}{c|ccc}
State & $c$ & $d$ & \$\\
\hline 
0 & s3 & s4 & \\
1 &    &    & acc \\
2 & s6 & s7 & \\
3 & s3 & s4 & \\
4 & r3 & r3 & \\
5 & & & r1\\
6 & s6 & s7 & \\
7 & & & r3\\
8 & r2 & r2 & \\
9 & & & r2
\end{tabular} 
\end{center}


The rows represent different states. 
The columns represent the terminal symbols of the grammar. 
The value of each cell can be empty, a shift, a reduce or an accept action.  

A shift action will consume a token from the token stream and move to a new state. 
For example, s6 will perform a shift and move to state 6.

A reduce action returns to a previously encountered state and references a grammar rule that is being reduced.

An accept action is defined only once in the entire table. Once it is encountered, the parsing process is complete and the input has been successfully parsed.

The second table is the goto table. 

\begin{center}
\begin{tabular}{c|cc}
State & $S$ & $C$\\
\hline 
0 & 1 & 2\\
1 &    &     \\
2 &  & 5 \\
3 &  & 8  \\
4 &  &   \\
5 &  & \\
6 &  & 9 \\
7 &  & \\
8 &  &  \\
9 &  & 
\end{tabular} 
\end{center}

The columns represent the non-terminal symbols of the grammar. 
The content of each cell can be either a reference to another state or empty.

The parser itself maintains a stack of states. 
The top of the stack is the current state being processed. 
The parser reads the current token from the token stream provided by the lexer and gets the current action from the action table.
Depending on the action type, different behaviors apply.

On a shift action the parser will shift the position in the token stream and continue in the next iteration with a new token. 
The new state defined in the shift action is pushed to the stack. Then the next iteration is started.

On a reduce action, the parser will pop $n$ states from the stack, where $n$ is equal to the number of terminal and nonterminal 
symbols to the right of the grammar rule. Then the new top of stack is read and the state defined in the goto 
table, and the current token in the token stream is pushed onto the stack.

On an accept action, the parser will complete the parsing process by accepting the input. 
